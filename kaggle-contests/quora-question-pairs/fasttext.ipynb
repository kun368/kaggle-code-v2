{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c quora-question-pairs\n",
    "# !pip install diff_match_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(pathlib.Path(os.getcwd()).parent.parent))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import fasttext.util\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "from utils.common import compress_read\n",
    "from utils.shared_code import to_kaggle_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df = compress_read('./data/train.csv')\n",
    "pred_df = compress_read('./data/test.csv')\n",
    "sample_submission_df = compress_read('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Graph Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "question_counter = Counter()\n",
    "question_answers = defaultdict(set)\n",
    "\n",
    "for q1, q2 in zip(train_df['question1'].values, train_df['question2'].values):\n",
    "    question_counter.update([q1, q2])\n",
    "    question_answers[q1].add(q2)\n",
    "    question_answers[q2].add(q1)\n",
    "\n",
    "for q1, q2 in zip(pred_df['question1'].values, pred_df['question2'].values):\n",
    "    question_counter.update([q1, q2])\n",
    "    question_answers[q1].add(q2)\n",
    "    question_answers[q2].add(q1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cleaning_sentence_1(text):\n",
    "    import re\n",
    "    from string import punctuation\n",
    "\n",
    "    if text is None:\n",
    "        text = ' '\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"who's\", \"who is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"when's\", \"when is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"there's\", \"there is\", text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!./'+-=]\", \" \", text)\n",
    "    # Except for the above special cases, \"\\'s\" can only represent possessive case and should be replaced with \" \"\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\" m \", \" am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"60k\", \" 60000 \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e-mail\", \"email\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub(r\"quikly\", \"quickly\", text)\n",
    "    text = re.sub(r\" usa \", \" america \", text)\n",
    "    text = re.sub(r\" u s \", \" america \", text)\n",
    "    text = re.sub(r\" uk \", \" england \", text)\n",
    "    text = re.sub(r\"imrovement\", \"improvement\", text)\n",
    "    text = re.sub(r\"intially\", \"initially\", text)\n",
    "    text = re.sub(r\" dms \", \"direct messages \", text)\n",
    "    text = re.sub(r\"demonitization\", \"demonetization\", text)\n",
    "    text = re.sub(r\"actived\", \"active\", text)\n",
    "    text = re.sub(r\"kms\", \" kilometers \", text)\n",
    "    text = re.sub(r\" cs \", \" computer science \", text)\n",
    "    text = re.sub(r\" ds \", \" data science \", text)\n",
    "    text = re.sub(r\" ee \", \" electronic engineering \", text)\n",
    "    text = re.sub(r\" upvotes \", \" up votes \", text)\n",
    "    text = re.sub(r\" iphone \", \" phone \", text)\n",
    "    text = re.sub(r\"\\0rs \", \" rs \", text)\n",
    "    text = re.sub(r\"calender\", \"calendar\", text)\n",
    "    text = re.sub(r\"ios\", \"operating system\", text)\n",
    "    text = re.sub(r\"programing\", \"programming\", text)\n",
    "    text = re.sub(r\"bestfriend\", \"best friend\", text)\n",
    "    text = re.sub(r\"III\", \"3\", text)\n",
    "    text = re.sub(r\"the us\", \"america\", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" \", text)\n",
    "    text = re.sub(r\"/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" \", text)\n",
    "    text = re.sub(r\"\\+\", \" \", text)\n",
    "    text = re.sub(r\"-\", \" \", text)\n",
    "    text = re.sub(r\"=\", \" \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = \"\".join([c for c in text if c not in punctuation])\n",
    "    return text\n",
    "\n",
    "def cleaning_sentence_2(text):\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk import word_tokenize\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = word_tokenize(text)\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/19 08:07:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "from pyspark.sql.types import Row\n",
    "\n",
    "spark = SparkSession.builder.appName(\"pandas-on-spark\")\\\n",
    "    .config('spark.driver.memory', '8G')\\\n",
    "    .config('spark.driver.maxResultSize', '0')\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark_br_dict = dict()\n",
    "def get_or_upd_br(name, value):\n",
    "    if name not in spark_br_dict:\n",
    "        spark_br_dict[name] = spark.sparkContext.broadcast(value)\n",
    "    return spark_br_dict[name]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/19 08:23:08 WARN TaskSetManager: Stage 7 contains a task of very large size (3348 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/01/19 08:23:53 WARN TaskSetManager: Stage 10 contains a task of very large size (18920 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def run_save_clean_df(df, name, force_update=False):\n",
    "    target = f'./fasttext_data/{name}'\n",
    "    if force_update or not pathlib.Path(target).exists():\n",
    "        spark.createDataFrame(data=df)\\\n",
    "            .repartition(50)\\\n",
    "            .withColumn('question1_clean', F.udf(cleaning_sentence_1)(F.expr(\"question1\")))\\\n",
    "            .withColumn('question2_clean', F.udf(cleaning_sentence_1)(F.expr(\"question2\")))\\\n",
    "            .withColumn('question1_clean_stop', F.udf(cleaning_sentence_2)(F.expr(\"question1_clean\")))\\\n",
    "            .withColumn('question2_clean_stop', F.udf(cleaning_sentence_2)(F.expr(\"question2_clean\")))\\\n",
    "            .write.mode(\"overwrite\").parquet(target)\n",
    "\n",
    "run_save_clean_df(train_df, name='train_df', force_update=False)\n",
    "run_save_clean_df(pred_df, name='pred_df', force_update=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## FastText training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def generate_text(a, b):\n",
    "    question1 = str(a).replace('\\n', ' ')\n",
    "    question2 = str(b).replace('\\n', ' ')\n",
    "    if not question1 or not question2:\n",
    "        return None\n",
    "    split1 = {w.lower() for w in question1.split(' ')}\n",
    "    split2 = {w.lower() for w in question2.split(' ')}\n",
    "    text = set()\n",
    "    text |= {t for t in split1 & split2}\n",
    "    text |= {'$' + t for t in split1 ^ split2}\n",
    "    return ' '.join(text)\n",
    "\n",
    "train_df = spark.read.parquet('./fasttext_data/train_df').toPandas()\n",
    "train_dict, test_dict = train_test_split(train_df.sample(frac=1.0).to_dict(orient='records'), test_size=0.2)\n",
    "ft_q_name_1, ft_q_name_2 = 'question1_clean', 'question2_clean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 5M words\n",
      "Number of words:  45340\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 3914866 lr:  0.000000 avg.loss:  0.423556 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "text_list = []\n",
    "for i in train_dict:\n",
    "    label = '__label__' + str(i['is_duplicate'])\n",
    "    x = generate_text(i[ft_q_name_1], i[ft_q_name_2])\n",
    "    if x: text_list.append({'label': label, 'text': x})\n",
    "pd.DataFrame(text_list).to_csv('./fasttext_data/ft_train.txt', header=False, index=False, sep='\\t')\n",
    "\n",
    "model = fasttext.train_supervised(\n",
    "    './fasttext_data/ft_train.txt',\n",
    "    label_prefix=\"__label__\",\n",
    "    lr=0.1,\n",
    "    epoch=5,\n",
    "    verbose=2,\n",
    "    minCount=3,\n",
    ")\n",
    "model.save_model('./fasttext_data/ft_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8404    0.8625    0.8513     50972\n",
      "           1     0.7545    0.7206    0.7372     29886\n",
      "\n",
      "    accuracy                         0.8101     80858\n",
      "   macro avg     0.7975    0.7916    0.7942     80858\n",
      "weighted avg     0.8086    0.8101    0.8091     80858\n",
      "\n",
      "log_loss: 0.413582217448883\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "def fast_text_pred(a, b, model):\n",
    "    words = generate_text(a, b)\n",
    "    pred = model.predict(words, k=1)\n",
    "    pred_label = 0 if pred[0][0] == '__label__0' else 1\n",
    "    pred_score = pred[1][0] if pred_label == 1 else 1 - pred[1][0]\n",
    "    return pred_label, pred_score\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_pred_score = []\n",
    "for i in test_dict:\n",
    "    label = int(i['is_duplicate'])\n",
    "    pred_label, pred_score = fast_text_pred(i[ft_q_name_1], i[ft_q_name_2], model)\n",
    "    y_true.append(label)\n",
    "    y_pred.append(pred_label)\n",
    "    y_pred_score.append(pred_score)\n",
    "\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "print('log_loss:', log_loss(y_true, y_pred_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # submit directly using fasttext\n",
    "# submission = []\n",
    "# for i in pred_df.to_dict(orient='records'):\n",
    "#     pred_label, pred_score = fast_text_pred(i[q_name_1], i[q_name_2], model)\n",
    "#     submission.append({\n",
    "#         'test_id': i['test_id'],\n",
    "#         'is_duplicate': pred_score\n",
    "#     })\n",
    "# to_kaggle_submission(submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Engineering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def add_feature_ft(spark_df: DataFrame):\n",
    "    def calc(rows):\n",
    "        model = fasttext.load_model('./fasttext_data/ft_model')\n",
    "        for row in rows:\n",
    "            pred_label, pred_score = fast_text_pred(row[ft_q_name_1], row[ft_q_name_2], model)\n",
    "            yield Row(**row.asDict(), feature_ft_pred_label=int(pred_label), feature_ft_pred_score=float(pred_score))\n",
    "\n",
    "    rdd = spark_df.rdd.mapPartitions(calc)\n",
    "    return spark.createDataFrame(rdd)\n",
    "\n",
    "# add_feature_ft(spark.read.parquet('./fasttext_data/train_df').limit(10)).toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def add_feature_char_diff(spark_df: DataFrame):\n",
    "    def calc(q1, q2, way):\n",
    "        q1, q2 = str(q1), str(q2)\n",
    "        if way == 1:\n",
    "            return abs(len(q1) - len(q2))\n",
    "        elif way == 2:\n",
    "            return abs(len(q1) - len(q2)) / (len(q1) + len(q2) + 1)\n",
    "\n",
    "    func = partial(F.udf(calc), F.expr('question1'), F.expr('question2'))\n",
    "    return spark_df\\\n",
    "        .withColumn('feature_char_diff_1', func(F.expr(\"1\")).cast(\"float\"))\\\n",
    "        .withColumn('feature_char_diff_2', func(F.expr(\"2\")).cast(\"float\"))\n",
    "\n",
    "# add_feature_char_diff(spark.read.parquet('./fasttext_data/train_df').limit(10)).toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def add_feature_word_count(spark_df: DataFrame):\n",
    "    def calc(rows):\n",
    "        from nltk import word_tokenize\n",
    "        from collections import OrderedDict\n",
    "        for row in rows:\n",
    "            sources = {\n",
    "                '1': ('question1', 'question2'),\n",
    "                '2': ('question1_clean', 'question2_clean'),\n",
    "                '3': ('question1_clean_stop', 'question2_clean_stop'),\n",
    "            }\n",
    "            cur = OrderedDict(row.asDict())\n",
    "            for s_id, source in sources.items():\n",
    "                q1, q2 = cur[source[0]], cur[source[1]]\n",
    "                words1, words2 = set(word_tokenize(str(q1))), set(word_tokenize(str(q2)))\n",
    "                len1, len2 = len(words1), len(words2)\n",
    "                cur[f'feature_word_count_{s_id}_1'] = float(abs(len1 - len2))\n",
    "                cur[f'feature_word_count_{s_id}_2'] = float(abs(len1 - len2) / (len1 + len2 + 1))\n",
    "                cur[f'feature_word_count_{s_id}_3'] = len(words1 & words2) / (len(words1 | words2) + 1)\n",
    "                cur[f'feature_word_count_{s_id}_4'] = len(words1 & words2) / (min(len1, len2) + 1)\n",
    "            yield Row(**cur)\n",
    "\n",
    "    return spark.createDataFrame(spark_df.rdd.mapPartitions(calc))\n",
    "\n",
    "# add_feature_word_count(spark.read.parquet('./fasttext_data/train_df').limit(10)).toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def add_feature_first_word(spark_df: DataFrame):\n",
    "    def calc(q1, q2):\n",
    "        from nltk import word_tokenize\n",
    "        word_list1 = word_tokenize(str(q1))\n",
    "        word_list2 = word_tokenize(str(q2))\n",
    "        if word_list1 and word_list2:\n",
    "            return int(word_list1[0] == word_list2[0])\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    return spark_df.withColumn('feature_char_first_word', F.udf(calc)(F.expr('question1'), F.expr('question2')).cast(\"float\"))\n",
    "\n",
    "# add_feature_first_word(spark.read.parquet('./fasttext_data/train_df').limit(10)).toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def add_feature_graph(spark_df: DataFrame):\n",
    "    qa_br = get_or_upd_br('question_answers', question_answers)\n",
    "\n",
    "    def calc(rows):\n",
    "        for row in rows:\n",
    "            q1, q2 = str(row[\"question1\"]), str(row[\"question2\"])\n",
    "            a1 = qa_br.value[q1]\n",
    "            a2 = qa_br.value[q2]\n",
    "            yield Row(\n",
    "                **row.asDict(),\n",
    "                feature_graph_1=len(a1),\n",
    "                feature_graph_2=len(a2),\n",
    "                feature_graph_3=(len(a1) + len(a2)) / 2,\n",
    "                feature_graph_4=len(a1 & a2),\n",
    "                feature_graph_5=len(a1 & a2) / (len(a1 | a2) + 1),\n",
    "            )\n",
    "\n",
    "    return spark.createDataFrame(spark_df.rdd.mapPartitions(calc))\n",
    "\n",
    "# add_feature_graph(spark.read.parquet('./fasttext_data/train_df').limit(10)).toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def add_feature_sentiment(spark_df: DataFrame):\n",
    "    def calc(rows):\n",
    "        from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "        analyzer = SentimentIntensityAnalyzer()\n",
    "        for row in rows:\n",
    "            q1, q2 = str(row[\"question1\"]), str(row[\"question2\"])\n",
    "            s1, s2 = analyzer.polarity_scores(q1), analyzer.polarity_scores(q2)\n",
    "            yield Row(\n",
    "                **row.asDict(),\n",
    "                feature_sentiment_neg=float(abs(s1['neg'] - s2['neg'])),\n",
    "                feature_sentiment_neu=float(abs(s1['neu'] - s2['neu'])),\n",
    "                feature_sentiment_pos=float(abs(s1['pos'] - s2['pos'])),\n",
    "                feature_sentiment_compound=float(abs(s1['compound'] - s2['compound'])),\n",
    "            )\n",
    "\n",
    "    return spark.createDataFrame(spark_df.rdd.mapPartitions(calc))\n",
    "\n",
    "# add_feature_sentiment(spark.read.parquet('./fasttext_data/train_df').limit(10)).toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def add_all_features(spark_df: DataFrame):\n",
    "   spark_df = add_feature_ft(spark_df)\n",
    "   spark_df = add_feature_char_diff(spark_df)\n",
    "   spark_df = add_feature_word_count(spark_df)\n",
    "   spark_df = add_feature_first_word(spark_df)\n",
    "   spark_df = add_feature_graph(spark_df)\n",
    "   spark_df = add_feature_sentiment(spark_df)\n",
    "   return spark_df\n",
    "\n",
    "# add_all_features(spark.read.parquet('./fasttext_data/train_df').limit(10)).toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Final Model Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "22/01/19 08:31:10 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_df = add_all_features(spark.read.parquet('./fasttext_data/train_df')).cache()\n",
    "train_X = train_df.selectExpr(*[c for c in train_df.columns if str(c).startswith(\"feature_\")]).collect()\n",
    "train_y = train_df.selectExpr('is_duplicate').collect()\n",
    "train_df.unpersist()\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "train_y = np.array(train_y).reshape(-1)\n",
    "train_X, eval_X, train_y, eval_y = train_test_split(train_X, train_y, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kun/miniconda3/envs/py37-sci-v1/lib/python3.7/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 119384, number of negative: 204048\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4322\n",
      "[LightGBM] [Info] Number of data points in the train set: 323432, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369116 -> initscore=-0.536010\n",
      "[LightGBM] [Info] Start training from score -0.536010\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.8872900640629251"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(\n",
    "    silent=False,\n",
    "    n_estimators=30\n",
    ")\n",
    "model = lgbm.fit(train_X, train_y)\n",
    "model.score(train_X, train_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8902    0.9340    0.9116     50979\n",
      "           1     0.8771    0.8035    0.8387     29879\n",
      "\n",
      "    accuracy                         0.8858     80858\n",
      "   macro avg     0.8836    0.8687    0.8751     80858\n",
      "weighted avg     0.8854    0.8858    0.8846     80858\n",
      "\n",
      "log_loss: 0.26335183939513285\n"
     ]
    }
   ],
   "source": [
    "eval_pred = []\n",
    "eval_pred_score = []\n",
    "for s0, s1 in model.predict_proba(eval_X):\n",
    "    eval_pred.append(1 if s1 >= s0 else 0)\n",
    "    eval_pred_score.append(s1)\n",
    "print(classification_report(eval_y, eval_pred, digits=4))\n",
    "print('log_loss:', log_loss(eval_y, eval_pred_score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Final Submit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Traceback (most recent call last):                                              \n",
      "  File \"/home/kun/miniconda3/envs/py37-sci-v1/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 186, in manager\n",
      "  File \"/home/kun/miniconda3/envs/py37-sci-v1/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 74, in worker\n",
      "  File \"/home/kun/miniconda3/envs/py37-sci-v1/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 663, in main\n",
      "    if read_int(infile) == SpecialLengths.END_OF_STREAM:\n",
      "  File \"/home/kun/miniconda3/envs/py37-sci-v1/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 564, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pred_df = add_all_features(spark.read.parquet('./fasttext_data/pred_df').repartition(50)).cache()\n",
    "pred_X = pred_df.selectExpr(*[c for c in pred_df.columns if str(c).startswith(\"feature_\")]).collect()\n",
    "pred_id = pred_df.selectExpr('test_id').collect()\n",
    "train_df.unpersist()\n",
    "\n",
    "pred_X = np.array(pred_X)\n",
    "pred_id = np.array(pred_id).reshape(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "submission = []\n",
    "for test_id, (s0, s1) in zip(pred_id, model.predict_proba(pred_X)):\n",
    "    submission.append({\n",
    "        'test_id': test_id,\n",
    "        'is_duplicate': s1\n",
    "    })\n",
    "to_kaggle_submission(submission)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}