{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c quora-question-pairs\n",
    "# !pip install diff_match_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import sys, pathlib, os\n",
    "sys.path.append(str(pathlib.Path(os.getcwd()).parent.parent))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import fasttext.util\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.common import compress_read\n",
    "from utils.shared_code import to_kaggle_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df = compress_read('./data/train.csv')\n",
    "pred_df = compress_read('./data/test.csv')\n",
    "sample_submission_df = compress_read('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                            question  count\n0             What are the best ways to lose weight?    161\n1  How can you look at someone's private Instagra...    120\n2                     How can I lose weight quickly?    111\n3       What's the easiest way to make money online?     88\n4              Can you see who views your Instagram?     79",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What are the best ways to lose weight?</td>\n      <td>161</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>How can you look at someone's private Instagra...</td>\n      <td>120</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>How can I lose weight quickly?</td>\n      <td>111</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What's the easiest way to make money online?</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Can you see who views your Instagram?</td>\n      <td>79</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "question_counter = Counter()\n",
    "question_counter.update(train_df['question1'].values)\n",
    "question_counter.update(train_df['question2'].values)\n",
    "pd.DataFrame(question_counter.most_common(5), columns=['question', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cleaning_sentence_1(text):\n",
    "    import re\n",
    "    from string import punctuation\n",
    "\n",
    "    if text is None:\n",
    "        text = ' '\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"who's\", \"who is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"when's\", \"when is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"there's\", \"there is\", text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!./'+-=]\", \" \", text)\n",
    "    # Except for the above special cases, \"\\'s\" can only represent possessive case and should be replaced with \" \"\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\" m \", \" am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"60k\", \" 60000 \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e-mail\", \"email\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub(r\"quikly\", \"quickly\", text)\n",
    "    text = re.sub(r\" usa \", \" america \", text)\n",
    "    text = re.sub(r\" u s \", \" america \", text)\n",
    "    text = re.sub(r\" uk \", \" england \", text)\n",
    "    text = re.sub(r\"imrovement\", \"improvement\", text)\n",
    "    text = re.sub(r\"intially\", \"initially\", text)\n",
    "    text = re.sub(r\" dms \", \"direct messages \", text)\n",
    "    text = re.sub(r\"demonitization\", \"demonetization\", text)\n",
    "    text = re.sub(r\"actived\", \"active\", text)\n",
    "    text = re.sub(r\"kms\", \" kilometers \", text)\n",
    "    text = re.sub(r\" cs \", \" computer science \", text)\n",
    "    text = re.sub(r\" ds \", \" data science \", text)\n",
    "    text = re.sub(r\" ee \", \" electronic engineering \", text)\n",
    "    text = re.sub(r\" upvotes \", \" up votes \", text)\n",
    "    text = re.sub(r\" iphone \", \" phone \", text)\n",
    "    text = re.sub(r\"\\0rs \", \" rs \", text)\n",
    "    text = re.sub(r\"calender\", \"calendar\", text)\n",
    "    text = re.sub(r\"ios\", \"operating system\", text)\n",
    "    text = re.sub(r\"programing\", \"programming\", text)\n",
    "    text = re.sub(r\"bestfriend\", \"best friend\", text)\n",
    "    text = re.sub(r\"III\", \"3\", text)\n",
    "    text = re.sub(r\"the us\", \"america\", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" \", text)\n",
    "    text = re.sub(r\"/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" \", text)\n",
    "    text = re.sub(r\"\\+\", \" \", text)\n",
    "    text = re.sub(r\"-\", \" \", text)\n",
    "    text = re.sub(r\"=\", \" \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = \"\".join([c for c in text if c not in punctuation])\n",
    "    return text\n",
    "\n",
    "def cleaning_sentence_2(text):\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk import word_tokenize\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = word_tokenize(text)\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/16 10:14:05 WARN Utils: Your hostname, DESKTOP-QULA4OE resolves to a loopback address: 127.0.1.1; using 172.21.12.80 instead (on interface eth0)\n",
      "22/01/16 10:14:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/16 10:14:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder.appName(\"pandas-on-spark\")\\\n",
    "    .config('spark.driver.memory', '8G')\\\n",
    "    .config('spark.driver.maxResultSize', '0')\\\n",
    "    .getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def clean_df_save(df, name):\n",
    "    spark.createDataFrame(data=df)\\\n",
    "        .repartition(50)\\\n",
    "        .withColumn('question1_clean', F.udf(cleaning_sentence_1)(F.expr(\"question1\")))\\\n",
    "        .withColumn('question2_clean', F.udf(cleaning_sentence_1)(F.expr(\"question2\")))\\\n",
    "        .withColumn('question1_clean_stop', F.udf(cleaning_sentence_2)(F.expr(\"question1_clean\")))\\\n",
    "        .withColumn('question2_clean_stop', F.udf(cleaning_sentence_2)(F.expr(\"question2_clean\")))\\\n",
    "        .write.mode(\"overwrite\").parquet(f\"./fasttext_data/{name}\")\\\n",
    "\n",
    "# clean_df_save(train_df, 'train_df')\n",
    "# clean_df_save(pred_df, 'pred_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_df = spark.read.parquet('./fasttext_data/train_df').toPandas()\n",
    "pred_df = spark.read.parquet('./fasttext_data/pred_df').toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## FastText training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_text(a, b):\n",
    "    question1 = str(a).replace('\\n', ' ')\n",
    "    question2 = str(b).replace('\\n', ' ')\n",
    "    if not question1 or not question2:\n",
    "        return None\n",
    "    split1 = {w.lower() for w in question1.split(' ')}\n",
    "    split2 = {w.lower() for w in question2.split(' ')}\n",
    "    text = set()\n",
    "    text |= {t for t in split1 & split2}\n",
    "    text |= {'$' + t for t in split1 ^ split2}\n",
    "    return ' '.join(text)\n",
    "\n",
    "train_dict, test_dict = train_test_split(train_df.sample(frac=1.0).to_dict(orient='records'), test_size=0.2)\n",
    "q_name_1, q_name_2 = 'question1_clean', 'question2_clean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 5M words\n",
      "Number of words:  45321\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 2796713 lr:  0.000000 avg.loss:  0.420091 ETA:   0h 0m 0s 45.7% words/sec/thread: 2981458 lr:  0.054264 avg.loss:  0.454183 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "text_list = []\n",
    "for i in train_dict:\n",
    "    label = '__label__' + str(i['is_duplicate'])\n",
    "    x = generate_text(i[q_name_1], i[q_name_2])\n",
    "    if x: text_list.append({'label': label, 'text': x})\n",
    "pd.DataFrame(text_list).to_csv('ft_train.txt', header=False, index=False, sep='\\t')\n",
    "\n",
    "model = fasttext.train_supervised(\n",
    "    'ft_train.txt',\n",
    "    label_prefix=\"__label__\",\n",
    "    lr=0.1,\n",
    "    epoch=5,\n",
    "    verbose=2,\n",
    "    minCount=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8457    0.8613    0.8534     51052\n",
      "           1     0.7546    0.7308    0.7425     29806\n",
      "\n",
      "    accuracy                         0.8132     80858\n",
      "   macro avg     0.8001    0.7960    0.7979     80858\n",
      "weighted avg     0.8121    0.8132    0.8125     80858\n",
      "\n",
      "log_loss: 0.41356740247470447\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "def fast_text_pred(a, b):\n",
    "    words = generate_text(a, b)\n",
    "    pred = model.predict(words, k=1)\n",
    "    pred_label = 0 if pred[0][0] == '__label__0' else 1\n",
    "    pred_score = pred[1][0] if pred_label == 1 else 1 - pred[1][0]\n",
    "    return pred_label, pred_score\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_pred_score = []\n",
    "for i in test_dict:\n",
    "    label = int(i['is_duplicate'])\n",
    "    pred_label, pred_score = fast_text_pred(i[q_name_1], i[q_name_2])\n",
    "    y_true.append(label)\n",
    "    y_pred.append(pred_label)\n",
    "    y_pred_score.append(pred_score)\n",
    "\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "print('log_loss:', log_loss(y_true, y_pred_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# submit directly using fasttext\n",
    "submission = []\n",
    "for i in pred_df.to_dict(orient='records'):\n",
    "    pred_label, pred_score = fast_text_pred(i[q_name_1], i[q_name_2])\n",
    "    submission.append({\n",
    "        'test_id': i['test_id'],\n",
    "        'is_duplicate': pred_score\n",
    "    })\n",
    "to_kaggle_submission(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}