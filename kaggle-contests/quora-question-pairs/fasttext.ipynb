{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c quora-question-pairs\n",
    "# !pip install diff_match_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import fasttext.util\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def compress_read(f) -> pd.DataFrame:\n",
    "    import os.path as path\n",
    "    parquet_file = f.replace('.csv', '.parquet')\n",
    "    if str(f).endswith('.csv') and path.exists(f):\n",
    "        pd.read_csv(f).to_parquet(parquet_file, compression='brotli')\n",
    "    return pd.read_parquet(parquet_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df = compress_read('./data/train.csv')\n",
    "pred_df = compress_read('./data/test.csv')\n",
    "sample_submission_df = compress_read('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                             question  count\n0              What are the best ways to lose weight?    161\n1   How can you look at someone's private Instagra...    120\n2                      How can I lose weight quickly?    111\n3        What's the easiest way to make money online?     88\n4               Can you see who views your Instagram?     79\n..                                                ...    ...\n95              How can I improve fluency in English?     42\n96  How will scraping of 500 and 1000 rupees notes...     42\n97  How is black money curbed with the ban of 1000...     42\n98                 How do I really make money online?     42\n99  Why don't many people posting questions on Quo...     42\n\n[100 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What are the best ways to lose weight?</td>\n      <td>161</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>How can you look at someone's private Instagra...</td>\n      <td>120</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>How can I lose weight quickly?</td>\n      <td>111</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What's the easiest way to make money online?</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Can you see who views your Instagram?</td>\n      <td>79</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>How can I improve fluency in English?</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>How will scraping of 500 and 1000 rupees notes...</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>How is black money curbed with the ban of 1000...</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>How do I really make money online?</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Why don't many people posting questions on Quo...</td>\n      <td>42</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "question_counter = Counter()\n",
    "question_counter.update(train_df['question1'].values)\n",
    "question_counter.update(train_df['question2'].values)\n",
    "pd.DataFrame(question_counter.most_common(100), columns=['question', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cleaning_sentence_1(text):\n",
    "    import re\n",
    "    from string import punctuation\n",
    "\n",
    "    if text is None:\n",
    "        text = ' '\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"who's\", \"who is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"when's\", \"when is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"there's\", \"there is\", text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!./'+-=]\", \" \", text)\n",
    "    # Except for the above special cases, \"\\'s\" can only represent possessive case and should be replaced with \" \"\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\" m \", \" am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"60k\", \" 60000 \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e-mail\", \"email\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub(r\"quikly\", \"quickly\", text)\n",
    "    text = re.sub(r\" usa \", \" america \", text)\n",
    "    text = re.sub(r\" u s \", \" america \", text)\n",
    "    text = re.sub(r\" uk \", \" england \", text)\n",
    "    text = re.sub(r\"imrovement\", \"improvement\", text)\n",
    "    text = re.sub(r\"intially\", \"initially\", text)\n",
    "    text = re.sub(r\" dms \", \"direct messages \", text)\n",
    "    text = re.sub(r\"demonitization\", \"demonetization\", text)\n",
    "    text = re.sub(r\"actived\", \"active\", text)\n",
    "    text = re.sub(r\"kms\", \" kilometers \", text)\n",
    "    text = re.sub(r\" cs \", \" computer science \", text)\n",
    "    text = re.sub(r\" ds \", \" data science \", text)\n",
    "    text = re.sub(r\" ee \", \" electronic engineering \", text)\n",
    "    text = re.sub(r\" upvotes \", \" up votes \", text)\n",
    "    text = re.sub(r\" iphone \", \" phone \", text)\n",
    "    text = re.sub(r\"\\0rs \", \" rs \", text)\n",
    "    text = re.sub(r\"calender\", \"calendar\", text)\n",
    "    text = re.sub(r\"ios\", \"operating system\", text)\n",
    "    text = re.sub(r\"programing\", \"programming\", text)\n",
    "    text = re.sub(r\"bestfriend\", \"best friend\", text)\n",
    "    text = re.sub(r\"III\", \"3\", text)\n",
    "    text = re.sub(r\"the us\", \"america\", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" \", text)\n",
    "    text = re.sub(r\"/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" \", text)\n",
    "    text = re.sub(r\"\\+\", \" \", text)\n",
    "    text = re.sub(r\"-\", \" \", text)\n",
    "    text = re.sub(r\"=\", \" \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = \"\".join([c for c in text if c not in punctuation])\n",
    "    return text\n",
    "\n",
    "def cleaning_sentence_2(text):\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk import word_tokenize\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = word_tokenize(text)\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder.appName(\"pandas-on-spark\")\\\n",
    "    .config('spark.driver.memory', '8G')\\\n",
    "    .config('spark.driver.maxResultSize', '0')\\\n",
    "    .getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/16 08:04:22 WARN TaskSetManager: Stage 9 contains a task of very large size (3348 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/01/16 08:05:10 WARN TaskSetManager: Stage 12 contains a task of very large size (18920 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def clean_df_save(df, name):\n",
    "    spark.createDataFrame(data=df)\\\n",
    "        .repartition(50)\\\n",
    "        .withColumn('question1_original', F.expr('question1'))\\\n",
    "        .withColumn('question2_original', F.expr('question2'))\\\n",
    "        .withColumn('question1_clean', F.udf(cleaning_sentence_1)(F.expr(\"question1\")))\\\n",
    "        .withColumn('question2_clean', F.udf(cleaning_sentence_1)(F.expr(\"question2\")))\\\n",
    "        .withColumn('question1_clean_stop', F.udf(cleaning_sentence_2)(F.expr(\"question1_clean\")))\\\n",
    "        .withColumn('question2_clean_stop', F.udf(cleaning_sentence_2)(F.expr(\"question2_clean\")))\\\n",
    "        .write.mode(\"overwrite\").parquet(f\"./fasttext_data/{name}\")\\\n",
    "\n",
    "clean_df_save(train_df, 'train_df')\n",
    "clean_df_save(pred_df, 'pred_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_df = spark.read.parquet('./fasttext_data/train_df').toPandas()\n",
    "pred_df = spark.read.parquet('./fasttext_data/pred_df').toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## FastText training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_text(a, b):\n",
    "    question1 = str(a).replace('\\n', ' ')\n",
    "    question2 = str(b).replace('\\n', ' ')\n",
    "    if not question1 or not question2:\n",
    "        return None\n",
    "    split1 = {w.lower() for w in question1.split(' ')}\n",
    "    split2 = {w.lower() for w in question2.split(' ')}\n",
    "    text = set()\n",
    "    text |= {t for t in split1 & split2}\n",
    "    text |= {'$' + t for t in split1 ^ split2}\n",
    "    return ' '.join(text)\n",
    "\n",
    "train_dict, test_dict = train_test_split(train_df.sample(frac=1.0).to_dict(orient='records'), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 6M words\n",
      "Number of words:  71235\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 2502543 lr:  0.000000 avg.loss:  0.410507 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "text_list = []\n",
    "for i in train_dict:\n",
    "    label = '__label__' + str(i['is_duplicate'])\n",
    "    x = generate_text(i['question1'], i['question2'])\n",
    "    if x: text_list.append({'label': label, 'text': x})\n",
    "pd.DataFrame(text_list).to_csv('ft_train.txt', header=False, index=False, sep='\\t')\n",
    "\n",
    "model = fasttext.train_supervised(\n",
    "    'ft_train.txt',\n",
    "    label_prefix=\"__label__\",\n",
    "    lr=0.1,\n",
    "    epoch=5,\n",
    "    verbose=2,\n",
    "    minCount=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8413    0.8729    0.8568     51035\n",
      "           1     0.7675    0.7181    0.7420     29823\n",
      "\n",
      "    accuracy                         0.8158     80858\n",
      "   macro avg     0.8044    0.7955    0.7994     80858\n",
      "weighted avg     0.8140    0.8158    0.8144     80858\n",
      "\n",
      "log_loss: 0.417073991886548\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "def fast_text_pred(a, b):\n",
    "    words = generate_text(a, b)\n",
    "    pred = model.predict(words, k=1)\n",
    "    pred_label = 0 if pred[0][0] == '__label__0' else 1\n",
    "    pred_score = pred[1][0] if pred_label == 1 else 1 - pred[1][0]\n",
    "    return pred_label, pred_score\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_pred_score = []\n",
    "for i in test_dict:\n",
    "    label = int(i['is_duplicate'])\n",
    "    pred_label, pred_score = fast_text_pred(i['question1'], i['question2'])\n",
    "    y_true.append(label)\n",
    "    y_pred.append(pred_label)\n",
    "    y_pred_score.append(pred_score)\n",
    "\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "print('log_loss:', log_loss(y_true, y_pred_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# submit directly using fasttext\n",
    "# submission = []\n",
    "# for i in pred_df.to_dict(orient='records'):\n",
    "#     pred_label, pred_score = fast_text_pred(i['question1'], i['question2'])\n",
    "#     submission.append({\n",
    "#         'test_id': i['test_id'],\n",
    "#         'is_duplicate': pred_score\n",
    "#     })\n",
    "# to_kaggle_submission(submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}