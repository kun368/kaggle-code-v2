{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from bidict import bidict\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class FastTextSiamese(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocab_size: int,\n",
    "            emb_size: int = 100,\n",
    "            hidden_size: int = 10\n",
    "    ) -> None:\n",
    "        super(FastTextSiamese, self).__init__()\n",
    "        self.embeddings = nn.EmbeddingBag(vocab_size, emb_size, mode='mean')\n",
    "        self.hidden = nn.Sequential(nn.Linear(emb_size, hidden_size), nn.ReLU())\n",
    "        self.out = nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward_once(self, text: torch.Tensor) -> torch.Tensor:\n",
    "        embeddings = self.embeddings(text)\n",
    "        return self.hidden(embeddings)\n",
    "\n",
    "    def forward(self, text1: torch.Tensor, text2: torch.Tensor) -> torch.Tensor:\n",
    "        out1 = self.forward_once(text1)\n",
    "        out2 = self.forward_once(text2)\n",
    "        dis = torch.abs(out1 - out2)\n",
    "        return self.out(dis)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def read_parquet_folder(split):\n",
    "    p = \"D:/Code/Pycharm/kaggle-code-v2/kaggle-contests/quora-question-pairs/fasttext_data\"\n",
    "    return pd.concat(\n",
    "        [pd.read_parquet(f) for f in glob.glob(f\"{p}/{split}/*\") if str(f).endswith('.parquet')],\n",
    "        axis=0, ignore_index=True\n",
    "    )\n",
    "\n",
    "train_df, valid_df = train_test_split(read_parquet_folder('train_df'), test_size=0.2, shuffle=True)\n",
    "pred_df = read_parquet_folder('pred_df')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "word_counter = Counter()\n",
    "sentence_word_limit = 30\n",
    "word_min_count = 3\n",
    "for ixd, i in train_df.iterrows():\n",
    "    w1 = nltk.word_tokenize(str(i['question1']))\n",
    "    w2 = nltk.word_tokenize(str(i['question2']))\n",
    "    word_counter.update(w1)\n",
    "    word_counter.update(w2)\n",
    "\n",
    "word_id_mapping = bidict(enumerate([k for k, v in word_counter.items() if v >= word_min_count]))\n",
    "word_id_mapping.inv['<pad>'] = len(word_id_mapping)\n",
    "word_id_mapping.inv['<unk>'] = len(word_id_mapping)\n",
    "\n",
    "def sentence_to_ids(text):\n",
    "    words = nltk.word_tokenize(str(text))[:sentence_word_limit]\n",
    "    words = [word_id_mapping.inv.get(i, word_id_mapping.inv['<unk>']) for i in words]\n",
    "    words += [word_id_mapping.inv['<pad>']] * (sentence_word_limit - len(words))\n",
    "    return words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class QuoraDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df_dict = df.to_dict(orient='records')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_dict)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cur = self.df_dict[idx]\n",
    "        t1 = sentence_to_ids(cur['question1'])\n",
    "        t2 = sentence_to_ids(cur['question2'])\n",
    "        label = cur.get('is_duplicate', 0)\n",
    "        return torch.LongTensor(t1).to(device), torch.LongTensor(t2).to(device), torch.LongTensor([label]).to(device)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "train_dl = DataLoader(QuoraDataset(train_df), batch_size, shuffle=False)\n",
    "valid_dl = DataLoader(QuoraDataset(valid_df), batch_size, shuffle=False)\n",
    "pred_dl = DataLoader(QuoraDataset(pred_df), batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class Summer:\n",
    "    def __init__(self):\n",
    "        self.sum_num = 0.0\n",
    "        self.sum_weight = 0.0\n",
    "\n",
    "    @staticmethod\n",
    "    def convert(n):\n",
    "        from typing import Iterable\n",
    "        if isinstance(n, Iterable):\n",
    "            n = next(iter(n))\n",
    "        return float(n)\n",
    "\n",
    "    def add(self, num, weight=1.0):\n",
    "        self.sum_num += self.convert(num)\n",
    "        self.sum_weight += self.convert(weight)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"{:.4f}\".format(self.sum_num / self.sum_weight)\n",
    "\n",
    "\n",
    "class MultiSummer:\n",
    "    def __init__(self):\n",
    "        self.summers = OrderedDict()\n",
    "\n",
    "    def put(self, key, num, weight=1.0):\n",
    "        if key not in self.summers:\n",
    "            self.summers[key] = Summer()\n",
    "        self.summers[key].add(num, weight)\n",
    "\n",
    "    def get(self, key):\n",
    "        return self.summers.get(key, Summer())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size 46220\n",
      "==================================================================\n",
      "                   Kernel Shape Output Shape  Params Mult-Adds\n",
      "Layer                                                         \n",
      "0_embeddings       [100, 46220]    [64, 100]  4.622M    4.622M\n",
      "1_hidden.Linear_0     [100, 10]     [64, 10]   1.01k      1.0k\n",
      "2_hidden.ReLU_1               -     [64, 10]       -         -\n",
      "3_embeddings       [100, 46220]    [64, 100]       -    4.622M\n",
      "4_hidden.Linear_0     [100, 10]     [64, 10]       -      1.0k\n",
      "5_hidden.ReLU_1               -     [64, 10]       -         -\n",
      "6_out                   [10, 2]      [64, 2]    22.0      20.0\n",
      "------------------------------------------------------------------\n",
      "                         Totals\n",
      "Total params          4.623032M\n",
      "Trainable params      4.623032M\n",
      "Non-trainable params        0.0\n",
      "Mult-Adds              9.24602M\n",
      "==================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Pycharm\\ml_learning\\conda_env\\lib\\site-packages\\torchsummaryX\\torchsummaryX.py:101: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_sum = df.sum()\n"
     ]
    },
    {
     "data": {
      "text/plain": "                   Kernel Shape Output Shape     Params  Mult-Adds\nLayer                                                             \n0_embeddings       [100, 46220]    [64, 100]  4622000.0  4622000.0\n1_hidden.Linear_0     [100, 10]     [64, 10]     1010.0     1000.0\n2_hidden.ReLU_1               -     [64, 10]        NaN        NaN\n3_embeddings       [100, 46220]    [64, 100]        NaN  4622000.0\n4_hidden.Linear_0     [100, 10]     [64, 10]        NaN     1000.0\n5_hidden.ReLU_1               -     [64, 10]        NaN        NaN\n6_out                   [10, 2]      [64, 2]       22.0       20.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Kernel Shape</th>\n      <th>Output Shape</th>\n      <th>Params</th>\n      <th>Mult-Adds</th>\n    </tr>\n    <tr>\n      <th>Layer</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0_embeddings</th>\n      <td>[100, 46220]</td>\n      <td>[64, 100]</td>\n      <td>4622000.0</td>\n      <td>4622000.0</td>\n    </tr>\n    <tr>\n      <th>1_hidden.Linear_0</th>\n      <td>[100, 10]</td>\n      <td>[64, 10]</td>\n      <td>1010.0</td>\n      <td>1000.0</td>\n    </tr>\n    <tr>\n      <th>2_hidden.ReLU_1</th>\n      <td>-</td>\n      <td>[64, 10]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3_embeddings</th>\n      <td>[100, 46220]</td>\n      <td>[64, 100]</td>\n      <td>NaN</td>\n      <td>4622000.0</td>\n    </tr>\n    <tr>\n      <th>4_hidden.Linear_0</th>\n      <td>[100, 10]</td>\n      <td>[64, 10]</td>\n      <td>NaN</td>\n      <td>1000.0</td>\n    </tr>\n    <tr>\n      <th>5_hidden.ReLU_1</th>\n      <td>-</td>\n      <td>[64, 10]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6_out</th>\n      <td>[10, 2]</td>\n      <td>[64, 2]</td>\n      <td>22.0</td>\n      <td>20.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummaryX import summary\n",
    "\n",
    "vocab_size = len(word_id_mapping)\n",
    "print('vocab_size', vocab_size)\n",
    "sample = torch.zeros(size=(batch_size, sentence_word_limit), dtype=torch.int64)\n",
    "summary(FastTextSiamese(vocab_size=vocab_size), x=sample, text2=sample)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/5054 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ea173b8e78141a9a718734db5ecb9a7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1264 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61daffed17e149219819216520c9e640"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5054 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "80fe41b57e7b49da8f05557d303f1204"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1264 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4fa8dd1eede14faca9bb74099ffc0737"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5054 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4cd3ea00b6d344d4810496ddc2bf31cd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1264 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7594365fc4ee464fb2fb232a4e391703"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5054 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89796ef5733f4cbe8fd9ec85efa2293a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1264 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e81f87dd4e8c454683182062f94be9fe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5054 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cf0e2426a3a44a5cbd5ef6c848b37f24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1264 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1669a10acc0d4670a1d97eabce05a9bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5054 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b47568473164ce28e1a5c712d119927"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1264 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "379f149a98bd46419da975fe692a64bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5054 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "084184da50e642a9945b258091a2e00f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1264 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32b42472a727466abf42aeea187d0c17"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5054 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7abdb19c354642b6ab74567003875f08"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1264 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2eeefff94e174bd3b406d4102ffe2f1d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5054 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8aab60b650a84598ae6d3d035d25de79"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1264 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b719276359c746baa4a606a919aa8bdb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5054 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7bccfc5bb43d4b0e8af0cfb74238d2dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1264 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dbf368f630ba49f2a55b384231ae7a36"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "net = FastTextSiamese(vocab_size=vocab_size).to(device)\n",
    "optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, net.parameters()))\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "tot_epoch = 10\n",
    "for epoch in range(tot_epoch):\n",
    "    def run(data_loader, is_train=True):\n",
    "        net.train(is_train)\n",
    "        pbar = tqdm(iterable=data_loader, colour='#1d3557' if is_train else '#457b9d')\n",
    "        summer = MultiSummer()\n",
    "        for t1, t2, labels in pbar:\n",
    "            labels = torch.squeeze(labels)\n",
    "            y_hat = net(t1, t2)\n",
    "            loss = loss_func(y_hat, labels)\n",
    "            # metrics\n",
    "            local_real, local_pred = labels.detach().cpu(), np.argmax(y_hat.detach().cpu(), axis=1)\n",
    "            summer.put('loss', loss.item())\n",
    "            summer.put('precision', precision_score(local_real, local_pred, zero_division=0))\n",
    "            summer.put('recall', recall_score(local_real, local_pred, zero_division=0))\n",
    "            if is_train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            pbar.set_description(\n",
    "                f'Epoch {epoch + 1}/{tot_epoch} - '\n",
    "                f'loss: {summer.get(\"loss\")} '\n",
    "                f'precision: {summer.get(\"precision\")} '\n",
    "                f'recall: {summer.get(\"recall\")} '\n",
    "            )\n",
    "\n",
    "\n",
    "    run(train_dl, is_train=True)\n",
    "    run(valid_dl, is_train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}